{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab13913-0cf2-4bf0-941d-3e8dec4f4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Name: <YOUR NAME>\n",
    "Email: <YOUR GRADESCOPE EMAIL>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e23a911-c99d-46de-aa34-6bc4c4de53b9",
   "metadata": {},
   "source": [
    "# Program 3: geospatial analysis of 911 ambulance requests in NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7cb859-6726-4a3e-9e13-37fe6300aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from plotly import express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93fc09b-6b5f-4322-b644-82b0979a3196",
   "metadata": {},
   "source": [
    "## Section 1: obtain and explore the data\n",
    "\n",
    "In this exercise you'll be working with with the [NYPD 911 Calls For Service dataset](https://data.cityofnewyork.us/Public-Safety/NYPD-Calls-for-Service-Year-to-Date-/n2zq-pubd/about_data). In particular, you'll be looking at a subset of the data: ambulance calls between 2024-01-01 and 2024-09-31.\n",
    "\n",
    "#### Task 1.1: Download and import the data\n",
    "Export the Ambulance calls data table from the NYC Open Data portal. You can find the subset with the necessary filters applied (and some non-necessary columns removed) [here](https://data.cityofnewyork.us/Public-Safety/NYPD-Calls-for-Service-Year-to-Date-/n2zq-pubd/explore/query/SELECT%0A%20%20%60incident_date%60%2C%0A%20%20%60incident_time%60%2C%0A%20%20%60boro_nm%60%2C%0A%20%20%60typ_desc%60%2C%0A%20%20%60arrivd_ts%60%2C%0A%20%20%60closng_ts%60%2C%0A%20%20%60latitude%60%2C%0A%20%20%60longitude%60%0AWHERE%0A%20%20%28%60create_date%60%0A%20%20%20%20%20BETWEEN%20%222024-01-01T00%3A00%3A00%22%20%3A%3A%20floating_timestamp%0A%20%20%20%20%20AND%20%222024-10-01T00%3A00%3A00%22%20%3A%3A%20floating_timestamp%29%0A%20%20AND%20caseless_contains%28%60typ_desc%60%2C%20%22AMBULANCE%20CASE%3A%22%29/page/filter). Export it as a CSV, move it to your notebook's working directory, and name your file `911-ambulance-calls-2024-Jan-Sep.csv`. Finally, import the data into a pandas dataframe named `ambulance_calls_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a394218-361a-4b10-8630-28bf3c8eea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambulance_calls_df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c9baa6-ca7e-4075-9e7a-f9756789b9c2",
   "metadata": {},
   "source": [
    "#### Task 1.2 Clean up the table\n",
    "\n",
    "1. rename `CLOSNG_TS` to `closing_ts` and `ARRIVD_TS` to `arrived_ts` for readability; then convert them to datetime type. You may want to consult the docs for the `pd.to_datetime()` function and python's datetime string formatting options [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) and [here](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior).\n",
    "1. combine `\"INCIDENT_DATE\"` and `\"INCIDENT_TIME\"` into a single datetime column called `\"incident_ts\"`; then, drop the original `\"INCIDENT_DATE\"` and `\"INCIDENT_TIME\"` to avoid redundancy\n",
    "1. make the remaining column names snake case for typing ease\n",
    "\n",
    "Finally, display the cleaned-up table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33dbe6-b7db-4242-975c-f7f0073fd354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up table\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554131f5-3984-4c2a-8ee0-33e75b41eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display cleaned table\n",
    "ambulance_calls_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623ccfa-03f8-4eb1-a636-17d7b95ebfd0",
   "metadata": {},
   "source": [
    "#### Task 1.3: Compute time intervals\n",
    "\n",
    "Before moving on, compute two new derived columns: the `total_seconds()` elapsed between\n",
    "- the incident was reported until it was closed; call the new column `\"duration_secs\"`\n",
    "- the incident was reported until help arrived; call this new column `\"arrived_in_secs\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f461a60-e5aa-4e26-b4ce-67661463979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create derived columns\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3450e-1732-46f2-ba15-0062f60f1e53",
   "metadata": {},
   "source": [
    "## Section 2: Exploratory analysis\n",
    "#### Task 2.1: Explore the time intervals\n",
    "Now that you've created these new columns, let's take a look at them. Start by showing summary stats of new columns you created using the `.describe()` method on those two columns. Pass the argument `percentiles=[.25, .5, .75, .9, .95]` to get the quartiles as well as the 90th and 95th percentiles. Transpose the table using the resulting `T` attribute for easier readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541377fc-86da-4650-b6c0-46a6f8e2ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe \"duration_secs\" column\n",
    "ambulance_calls_df[[\"duration_secs\", \"arrived_in_secs\"]]...(...).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395ea44-1c89-4dda-b91a-d91cec3b6967",
   "metadata": {},
   "source": [
    "Now plot the cumulative distribution functions using seaborn's `ecdfplot()` function. Plot both cumulative distributions together in the same chart, calling `sns.ecdfplot()` twice in the same notebook cell. Use the `label` parameter to add meaningful names to your legend. Also, call `plt.xlim()` to set the x-axis limits to `0-20000` and `plt.xlabel()` to set the label to `\"time in seconds\"`. Finally, call `plt.legend()` to generate a legend in your chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84f13e-24af-4b6d-8333-4241752d05ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cumulative distribution plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.ecdfplot(...)\n",
    "sns.ecdfplot(...)\n",
    "plt....((0, 20000))\n",
    "plt....(\"time in seconds\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d509640-a9c9-45e6-8b7c-04a5a2449381",
   "metadata": {},
   "source": [
    "#### Task 2.2: Conclusions about time series intervals\n",
    "What conclusions do you reach after analyzing these two variables? Write at least three observations:\n",
    "\n",
    "> - 2.2 #1: ...\n",
    "> - 2.2 #2: ...\n",
    "> - 2.2 #3: ...\n",
    "> \n",
    "> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb6ed20-94a9-4d2f-a0c5-d0f4916ee2b8",
   "metadata": {},
   "source": [
    "#### Task 2.3: Probability distributions by borough\n",
    "\n",
    "Now, let's look at these distributions by borough. You will do so via kernel density estimation plots with `sns.kdeplot()`.\n",
    "\n",
    "First though, call matplotlib `plt.subplots()` to make a chart with two columns and a figure size of `(12, 4)`, storing the function outputs (a tuple) as `fig, ax`. Then invoke `sns.kdeplot()`, passing the the `hue` parameter so that each borough is represented with a different line. To treat each borough times as independent distributions, set the `common_norm` parameter to `False`. And to assign the chart to each of the two subplots, you'll need to pass the values `ax[0]` or `ax[1]` to the `ax` parameter. Finally, cut out the outliers from the KDE setting `clip` to `(-1, 20000)` for the `\"duration_secs\"` column and to `(-1, 10000)` for the `\"arrived_in_secs\"` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c57bf2-f43b-42e5-a42b-fa587042fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make KDE plots\n",
    "fig, ax = ...\n",
    "\n",
    "sns.kdeplot(..., ax=ax[0])\n",
    "sns.kdeplot(..., ax=ax[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e81f1-5e7b-4f7d-9740-1d1fd3a94e85",
   "metadata": {},
   "source": [
    "What stands out to you from these charts? Make at least two observations.\n",
    "\n",
    "> - 2.3 #1: ...\n",
    "> - 2.3 #2: ...\n",
    ">   \n",
    "> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490fec9-c95f-43e8-a5b8-72ecc34e52da",
   "metadata": {},
   "source": [
    "## Section 3: Aggregations in a choropleth map\n",
    "\n",
    "You saw that the 911 calls requesting an ambulance all have a latitude and longitude associated with them. That allows us to represent data geographically on a map!\n",
    "\n",
    "#### Task 3.1: Get NYC boro geometries\n",
    "First, you'll need the shapefiles or geojson files with the NYC borough boundaries. You can find them [here](https://data.cityofnewyork.us/City-Government/Borough-Boundaries/gthc-hcne). Download the borough boundaries in geojson format, move it to your notebook's working directory, and call your file `borough-boundaries.geojson`. \n",
    "\n",
    "Then, use the [geopandas](https://geopandas.org/en/stable/index.html) library, imported above as `gpd`. First, use the `read_file()` function to read your geojson file into a geodataframe called `nyc_boros`. Then, display the geodataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a2e4a-6caa-4090-bd17-fafd32a67183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read geojson file into a geopandas geodataframe\n",
    "nyc_boros = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c67700-8c32-4899-acc0-5be18aae05bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the geodataframe with the NYC boroughs\n",
    "nyc_boros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba445360-e093-4fb8-9b2e-75fd729fb81c",
   "metadata": {},
   "source": [
    "#### Task 3.2: First look at a geodataframe\n",
    "\n",
    "This is (probably) your first time looking at a geodataframe. What do you notice? Write at least two observations:\n",
    "\n",
    "> - 3.2 #1: ...\n",
    "> - 3.2 #2: ...\n",
    "> - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d14d0a-6a36-400b-afb1-9b1b7facb10c",
   "metadata": {},
   "source": [
    "#### Task 3.3: Choropleth map of typical arrival times by borough\n",
    "Now let's use these geometries together with the ambulance data to make an interactive choropleth map of the typical arrival time of help after a call is made on the five boroughs. You will also display other quantities a hover properties.\n",
    "\n",
    "First off, aggregate `ambulance_calls_df` into a new dataframe called `calls_by_boro` which should have the following columns: \n",
    "- `\"boro_nm\"`\n",
    "- `\"num_calls\"`\n",
    "- `\"median_arrived_in_secs\"`\n",
    "- `\"median_duration_secs\"`\n",
    "\n",
    "Before you group your dataframe, you should remove any rows where `\"arrived_in_secs\"` is not larger than `0` (clearly something is wrong with those data points), as well as rows where the borough name or the `\"arrived_ts\"` are null or missing. \n",
    "\n",
    "_**Hint**: you may find the `.agg()` dataframe method helpful to apply different aggregation functions to different columns._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969e575-c406-4a22-85ce-b29379a7ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate ambulance_calls_df by borough\n",
    "calls_by_boro = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec40691-c645-4056-9f21-e2de051bcc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the dataframe\n",
    "calls_by_boro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24227ff-4771-4169-8877-4b91a35d577a",
   "metadata": {},
   "source": [
    "Then, merge the `calls_by_boro` pandas dataframe into the `nyc_boros` geodataframe. Make sure to call `nyc_boros.merge(...)`, as the resulting object will preserve the type of the left frame. Name the new table `choropleth_gdf`. Finally, set the frame's index to `\"boro_name\"` and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85509b7f-005c-482d-ab35-cca9fbaaaffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "choropleth_gdf = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42aad94-6733-47fe-91db-612b641f1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the new geodataframe\n",
    "choropleth_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ef5fe-5a3d-4674-9378-d1830fa21448",
   "metadata": {},
   "source": [
    "Now you have a single geodataframe with the geometries for each borough and a number of metrics describing them. This is all you need to make your choropleth map with plotly.\n",
    "\n",
    "You'll be using the `choropleth_mapbox(...)` function of the `plotly.express` module (imported above with the typical alias `px`). You can find the documentation [here](https://plotly.com/python-api-reference/generated/plotly.express.choropleth_mapbox.html). Call the function setting the following parameters:\n",
    "- `data_frame`: this is your geodataframe containing the borough-level data; it's important that the index is a unique label to each geometry.\n",
    "- `geojson`: an array or `pandas.Series` with the geometries associated to each element.\n",
    "- `locations`: an array containing your location identifiers. In our case, `choropleth_gdf.index` is a good choice.\n",
    "- `color`: column name contaning values to be represented in choropleth: `\"median_arrived_in_secs\"`\n",
    "- `hover_data`: additional column names with data to be represented when hovering over a geometry; let's include `[\"num_calls\", \"median_duration_secs\"]`, but feel free to add others.\n",
    "- `labels`: a dictionary with the display names for different plot properties. Use this to make your column names more human readable:\n",
    "  -  `\"boro_name\": \"borough\"` \n",
    "  - `\"num_calls\": \"number of calls\"`\n",
    "  - `\"median_arrived_in_secs\": \"median arrival time (seconds)\"`\n",
    "  - `\"median_duration_secs\": \"median duration time (seconds)\"`\n",
    "- `title` (optional): a title for your choropleth!\n",
    "- `mapbox_style`: set this to `\"carto-darkmatter\"` to make a map with a black background, but feel free to play with other styles too (see [docs](https://plotly.com/python-api-reference/generated/plotly.express.choropleth_mapbox.html)).\n",
    "- `center`: set this to `{\"lat\": 40.75, \"lon\": -74.0}` to center the map in NYC\n",
    "- `zoom`: set this to `9`:\n",
    "- `height`: set it to `750`\n",
    "- `width`: set it to `750`\n",
    "\n",
    "Store the output of your function call as `choropleth_fig`, and finally call `choropleth_fig.show();` to display your choropleth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07748d14-62dc-46d6-ba5e-085979d8c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make and show the choropleth\n",
    "choropleth_fig = px.choropleth_mapbox(\n",
    "    ...\n",
    ")\n",
    "\n",
    "choropleth_fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4accc7-b1c1-43d1-9d74-c03dbfad1d2c",
   "metadata": {},
   "source": [
    "#### Task 3.4: Analyze the choropleth\n",
    "What do you observe in your choropleth? Write at least two thoughts:\n",
    "\n",
    "> - 3.4 #1: ...\n",
    "> - 3.4 #2: ...\n",
    "> \n",
    "> - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d4d85-5a64-4bd9-87ca-f09ef030bea1",
   "metadata": {},
   "source": [
    "## Section 4: scatter map of individual calls\n",
    "Now let's make a geographic scatterplot of individual ambulance call arrival times using the `px.scatter_mapbox()` function (docs [here](https://plotly.com/python-api-reference/generated/plotly.express.scatter_mapbox.html)).\n",
    "\n",
    "For this map you won't need a geodataframe as `ambulance_calls_df` contains latitude and longitude columns and `scatter_mapbox()` can take those as arguments. \n",
    "\n",
    "#### Task 4.1: Make a new dataframe for the scattermap\n",
    "First, make a new pandas dataframe called `new_years_df` that is a subset of `ambulance_calls_df` with\n",
    "- `\"incident_ts\"` being equal to `\"2024-01-01\"`\n",
    "- no missing/null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3a2213-c9f4-40a8-bd32-cc32aa877dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_years_df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc79c61-246c-4625-9a1c-0dc316d8e249",
   "metadata": {},
   "source": [
    "#### Task 4.2: Create the scatter map\n",
    "Now you'll create your scatter map. You'll do this in two steps: first you'll create the scatter map, then you'll add the boro boundaries as another layer.\n",
    "\n",
    "Storing its result as `scatter_fig`, call `px.scatter_mapbox` passing the following parameters:\n",
    "- `data_frame`\n",
    "- `lat`\n",
    "- `lon`\n",
    "- `size`\n",
    "- `opacity`\n",
    "- `color`\n",
    "- `title`\n",
    "- `zoom`\n",
    "- `height`\n",
    "- `width`\n",
    "\n",
    "That will create the scatter map (feel free to check your work before moving on). Then, call `scatter_fig.update_layout()`, setting the `mapbox_layers` parameter to the following value:\n",
    "\n",
    "```python\n",
    "[{\n",
    "    \"type\": \"line\",\n",
    "    \"color\": \"white\",\n",
    "    \"opacity\": 0.5,\n",
    "    \"source\": json.loads(nyc_boros[\"geometry\"].to_json()),\n",
    "    \"line\": {\"width\": 0.1},\n",
    "}]\n",
    "```\n",
    "\n",
    "Finally, call `scatter_fig.update_layout(mapbox_style=\"carto-darkmatter\")` to set the theme and call `scatter_fig.show()` to display your map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc28d6-bf76-445d-b801-da74fd7b66bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_fig = px.scatter_mapbox(...\n",
    ")\n",
    "\n",
    "scatter_fig.update_layout(...)\n",
    "\n",
    "scatter_fig.update_layout(...)\n",
    "\n",
    "scatter_fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a9e7e-477c-49cd-9177-e7483be6e298",
   "metadata": {},
   "source": [
    "#### Task 4.3: The slowest arrival\n",
    "Zoom into your map and look aronud a bit. Can you spot the call with the slowest arrival? Write its latitude and longitude here:\n",
    "> - latitude: 40.681268 \t\n",
    "> - longitude: -73.892877"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
